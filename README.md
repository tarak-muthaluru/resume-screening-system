\# Resume Screening System (ATS-style Semantic Matcher)



This project is an ATS-style Resume Screening System that automatically compares candidate resumes against a Job Description (JD) using semantic similarity. It uses modern NLP embeddings (Sentence Transformers) to understand meaning, not just keywords, and ranks multiple resumes based on how well they match the JD.



The system is built as an end-to-end pipeline and exposed through a Streamlit web application so that users can upload resumes, paste a JD, and instantly get match scores and rankings.



---



\## ğŸš€ Key Features



\- \*\*PDF Resume Parsing\*\*  

&nbsp; Extracts text from PDF resumes using a dedicated I/O module.



\- \*\*Semantic Matching using Embeddings\*\*  

&nbsp; Uses the `all-MiniLM-L6-v2` model from `sentence-transformers` to convert both JD and resumes into vector embeddings.



\- \*\*Cosine Similarity Scoring\*\*  

&nbsp; Computes similarity scores between JD and each resume using cosine similarity.



\- \*\*Section-wise Analysis (Skills \& Experience)\*\*  

&nbsp; Extracts approximate \*\*Skills\*\* and \*\*Experience\*\* sections from resume text and computes:

&nbsp; - Overall JD vs Resume score  

&nbsp; - JD Skills vs Resume Skills score  

&nbsp; - JD Responsibilities vs Resume Experience score  



\- \*\*Multi-Resume Ranking\*\*  

&nbsp; Supports multiple resume uploads and ranks them based on relevance to the JD.



\- \*\*Streamlit Web UI\*\*  

&nbsp; Interactive interface to:

&nbsp; - Paste or edit JD text  

&nbsp; - Upload one or more resume PDFs  

&nbsp; - View ranked results in a clean table with human-readable match labels.



---



\## ğŸ§± Project Architecture / Workflow



1\. \*\*Input\*\*  

&nbsp;  - User enters/pastes a Job Description (overall, skills, responsibilities).  

&nbsp;  - User uploads one or more resume PDFs via the Streamlit UI.



2\. \*\*PDF Text Extraction (`file\_io.py`)\*\*  

&nbsp;  - Reads each PDF file.  

&nbsp;  - Extracts raw text from all pages.



3\. \*\*Text Cleaning \& Section Extraction (`resume\_sections.py`)\*\*  

&nbsp;  - Normalizes whitespace and basic formatting.  

&nbsp;  - Heuristically identifies sections like:

&nbsp;    - Skills  

&nbsp;    - Work/Professional Experience  

&nbsp;  - Returns section-wise text for further processing.



4\. \*\*Embedding Generation (`embedding.py`)\*\*  

&nbsp;  - Loads `all-MiniLM-L6-v2` from `sentence-transformers`.  

&nbsp;  - Converts:

&nbsp;    - JD overall text  

&nbsp;    - JD skills text  

&nbsp;    - JD responsibilities text  

&nbsp;    - Full resume text  

&nbsp;    - Resume skills section  

&nbsp;    - Resume experience section  

&nbsp;  - into numeric vector embeddings.



5\. \*\*Similarity Computation (`embedding.py`)\*\*  

&nbsp;  - Uses cosine similarity to compute:

&nbsp;    - Overall match (JD full vs Resume full)  

&nbsp;    - Skills match (JD skills vs Resume skills)  

&nbsp;    - Experience match (JD responsibilities vs Resume experience)



6\. \*\*Ranking \& Display (`app.py`)\*\*  

&nbsp;  - Combines scores into a structured result set.  

&nbsp;  - Sorts resumes by overall similarity (descending).  

&nbsp;  - Displays:

&nbsp;    - Rank  

&nbsp;    - Resume file name  

&nbsp;    - Overall, Skills, Experience match as percentage + qualitative label (Excellent/Good/Weak/Poor).



---



\## ğŸ›  Tech Stack



\*\*Language \& Environment\*\*

\- Python 3.x

\- Virtual Environment (`venv`)



\*\*Core Libraries\*\*

\- \[`sentence-transformers`](https://www.sbert.net/) â€“ semantic embeddings (`all-MiniLM-L6-v2`)

\- `torch` â€“ backend for the embedding model

\- `numpy` â€“ numerical operations and cosine similarity

\- PDF parsing library (`PyPDF2` / `pdfplumber` â€“ depending on implementation)

\- `re` (Python regex) â€“ text cleaning and section detection



\*\*Web UI\*\*

\- \[`streamlit`](https://streamlit.io/) â€“ interactive web app for resume upload and scoring



\*\*Development \& Utilities\*\*

\- Jupyter Notebook â€“ experimentation and prototyping

\- Git \& GitHub â€“ version control and repository hosting



---



\## ğŸ“ Project Structure



```text

resume-screen/

â”‚

â”œâ”€â”€ app.py                  # Streamlit app (UI + orchestration)

â”œâ”€â”€ embedding.py            # Model loading, get\_embedding(), similarity()

â”œâ”€â”€ file\_io.py              # PDF text extraction logic

â”œâ”€â”€ resume\_sections.py      # Resume section extraction (skills, experience)

â”œâ”€â”€ cleaning.py             # Text cleaning helpers (if used)

â”œâ”€â”€ requirements.txt        # Python dependencies

â”œâ”€â”€ jd.txt                  # Sample Job Description (optional)

â”‚

â”œâ”€â”€ sample\_data/            # Sample resumes and test files

â”‚   â”œâ”€â”€ scanned\_resume.pdf.pdf

â”‚   â”œâ”€â”€ resume\_pdf1.pdf.pdf

â”‚   â””â”€â”€ resume1.txt

â”‚

â”œâ”€â”€ cleaningpy.ipynb        # Notebook for text extraction \& cleaning experiments

â”œâ”€â”€ similarity\_demo.ipynb   # Notebook for similarity experiments

â”œâ”€â”€ test\_embedding.py       # Script to test embedding logic

â”œâ”€â”€ test\_similarity.py      # Script to test similarity logic

â”œâ”€â”€ test\_read\_txt.py        # Simple file reading tests

â”‚

â””â”€â”€ .gitignore              # Ignore virtual env, cache, temp files

\# Resume Screening System (ATS-style Semantic Matcher)



This project is an ATS-style Resume Screening System that automatically compares candidate resumes against a Job Description (JD) using semantic similarity. It uses modern NLP embeddings (Sentence Transformers) to understand meaning, not just keywords, and ranks multiple resumes based on how well they match the JD.



The system is built as an end-to-end pipeline and exposed through a Streamlit web application so that users can upload resumes, paste a JD, and instantly get match scores and rankings.



---



\## ğŸš€ Key Features



\- \*\*PDF Resume Parsing\*\*  

&nbsp; Extracts text from PDF resumes using a dedicated I/O module.



\- \*\*Semantic Matching using Embeddings\*\*  

&nbsp; Uses the `all-MiniLM-L6-v2` model from `sentence-transformers` to convert both JD and resumes into vector embeddings.



\- \*\*Cosine Similarity Scoring\*\*  

&nbsp; Computes similarity scores between JD and each resume using cosine similarity.



\- \*\*Section-wise Analysis (Skills \& Experience)\*\*  

&nbsp; Extracts approximate \*\*Skills\*\* and \*\*Experience\*\* sections from resume text and computes:

&nbsp; - Overall JD vs Resume score  

&nbsp; - JD Skills vs Resume Skills score  

&nbsp; - JD Responsibilities vs Resume Experience score  



\- \*\*Multi-Resume Ranking\*\*  

&nbsp; Supports multiple resume uploads and ranks them based on relevance to the JD.



\- \*\*Streamlit Web UI\*\*  

&nbsp; Interactive interface to:

&nbsp; - Paste or edit JD text  

&nbsp; - Upload one or more resume PDFs  

&nbsp; - View ranked results in a clean table with human-readable match labels.



---



\## ğŸ§± Project Architecture / Workflow



1\. \*\*Input\*\*  

&nbsp;  - User enters/pastes a Job Description (overall, skills, responsibilities).  

&nbsp;  - User uploads one or more resume PDFs via the Streamlit UI.



2\. \*\*PDF Text Extraction (`file\_io.py`)\*\*  

&nbsp;  - Reads each PDF file.  

&nbsp;  - Extracts raw text from all pages.



3\. \*\*Text Cleaning \& Section Extraction (`resume\_sections.py`)\*\*  

&nbsp;  - Normalizes whitespace and basic formatting.  

&nbsp;  - Heuristically identifies sections like:

&nbsp;    - Skills  

&nbsp;    - Work/Professional Experience  

&nbsp;  - Returns section-wise text for further processing.



4\. \*\*Embedding Generation (`embedding.py`)\*\*  

&nbsp;  - Loads `all-MiniLM-L6-v2` from `sentence-transformers`.  

&nbsp;  - Converts:

&nbsp;    - JD overall text  

&nbsp;    - JD skills text  

&nbsp;    - JD responsibilities text  

&nbsp;    - Full resume text  

&nbsp;    - Resume skills section  

&nbsp;    - Resume experience section  

&nbsp;  - into numeric vector embeddings.



5\. \*\*Similarity Computation (`embedding.py`)\*\*  

&nbsp;  - Uses cosine similarity to compute:

&nbsp;    - Overall match (JD full vs Resume full)  

&nbsp;    - Skills match (JD skills vs Resume skills)  

&nbsp;    - Experience match (JD responsibilities vs Resume experience)



6\. \*\*Ranking \& Display (`app.py`)\*\*  

&nbsp;  - Combines scores into a structured result set.  

&nbsp;  - Sorts resumes by overall similarity (descending).  

&nbsp;  - Displays:

&nbsp;    - Rank  

&nbsp;    - Resume file name  

&nbsp;    - Overall, Skills, Experience match as percentage + qualitative label (Excellent/Good/Weak/Poor).



---



\## ğŸ›  Tech Stack



\*\*Language \& Environment\*\*

\- Python 3.x

\- Virtual Environment (`venv`)



\*\*Core Libraries\*\*

\- \[`sentence-transformers`](https://www.sbert.net/) â€“ semantic embeddings (`all-MiniLM-L6-v2`)

\- `torch` â€“ backend for the embedding model

\- `numpy` â€“ numerical operations and cosine similarity

\- PDF parsing library (`PyPDF2` / `pdfplumber` â€“ depending on implementation)

\- `re` (Python regex) â€“ text cleaning and section detection



\*\*Web UI\*\*

\- \[`streamlit`](https://streamlit.io/) â€“ interactive web app for resume upload and scoring



\*\*Development \& Utilities\*\*

\- Jupyter Notebook â€“ experimentation and prototyping

\- Git \& GitHub â€“ version control and repository hosting



---



\## ğŸ“ Project Structure



```text

resume-screen/

â”‚

â”œâ”€â”€ app.py                  # Streamlit app (UI + orchestration)

â”œâ”€â”€ embedding.py            # Model loading, get\_embedding(), similarity()

â”œâ”€â”€ file\_io.py              # PDF text extraction logic

â”œâ”€â”€ resume\_sections.py      # Resume section extraction (skills, experience)

â”œâ”€â”€ cleaning.py             # Text cleaning helpers (if used)

â”œâ”€â”€ requirements.txt        # Python dependencies

â”œâ”€â”€ jd.txt                  # Sample Job Description (optional)

â”‚

â”œâ”€â”€ sample\_data/            # Sample resumes and test files

â”‚   â”œâ”€â”€ scanned\_resume.pdf.pdf

â”‚   â”œâ”€â”€ resume\_pdf1.pdf.pdf

â”‚   â””â”€â”€ resume1.txt

â”‚

â”œâ”€â”€ cleaningpy.ipynb        # Notebook for text extraction \& cleaning experiments

â”œâ”€â”€ similarity\_demo.ipynb   # Notebook for similarity experiments

â”œâ”€â”€ test\_embedding.py       # Script to test embedding logic

â”œâ”€â”€ test\_similarity.py      # Script to test similarity logic

â”œâ”€â”€ test\_read\_txt.py        # Simple file reading tests

â”‚

â””â”€â”€ .gitignore              # Ignore virtual env, cache, temp files



